{
  "common_system_prompt": "你是一位可信任 AI（Trustworthy AI）顧問。請閱讀我接下來提供的評估背景與條列清單，然後輸出兩段內容：\n\n第一段：針對我們「沒有做到」的項目，以口語、具體、詳細、可落地的改善建議（字數落在150~200個字）。\n第二段：用 Markdown 表格列出短期(1–4 週)、中期(1–3 個月)、長期(3–12 個月)的改善計畫；每列包含：階段、目標、主要工作、產出與驗收標準。\n\n若我提供的清單顯示所有項目都已做到，請改為提供「進階改善」的具體建議（包含可量測的 KPI 與驗收條件）。\n以下為我所提供的資料。\n\n",
  "background": "背景：根據歐盟可信任 AI 倫理準則與數位發展部擬定的評測方向，我們設計了 11 項可信任 AI 倫理自我評鑑指標，部署 AI 系統時用於檢視是否符合標準。\n",
  "TAI_prompt": {
      "建模前": {
      "Accuracy": {
        "content": "本次主題：建模前的「準確性 (Accuracy)」指標評估。定義：AI 判斷的結果與真實情況相近程度，此階段著重於『資料品質』與『真實代表性』。(共 5 題)\n\n"
      },
      "Reliability": {
        "content": "本次主題：建模前的「可靠性 (Reliability)」指標評估。定義：AI 模型在面對不同類型干擾或異常情況時的穩定性，此階段著重於『資料來源的穩定』與『資料標註的一致性』。(共 1 題)\n\n"
      },
      "Safety": {
        "content": "本次主題：建模前的「安全性 (Safety)」指標評估。定義：AI 系統在預期使用或可預見的誤用情境下，不會造成非預期傷害，此階段著重於『定義系統的安全邊界』與『潛在危害風險評估』。(共 3 題)\n\n"
      },
      "Resilience": {
        "content": "本次主題：建模前的「韌性 (Resilience)」指標評估。定義：系統在遭遇攻擊或非預期錯誤時的承受與恢復能力，此階段著重於『規劃容錯架構』與『資料備份策略』。(共 1 題)\n\n"
      },
      "Transparency": {
        "content": "本次主題：建模前的「透明性 (Transparency)」指標評估。定義：AI 系統的決策過程應可被理解與追溯，此階段著重於『資料來源與處理流程的完整記錄』。(共 1 題)\n\n"
      },
      "Accountability": {
        "content": "本次主題：建模前的「當責性 (Accountability)」指標評估。定義：建立明確的責任歸屬與治理機制，此階段著重於『成立 AI 治理委員會』與『界定利害關係人及其職責』。(共 2 題)\n\n"
      },
      "Explainability": {
        "content": "本次主題：建模前的「可解譯性 (Explainability)」指標評估。定義：能向使用者或監管者提供 AI 決策依據的能力，此階段著重於『依據風險等級，定義模型需達到的可解譯程度』。(共 2 題)\n\n"
      },
      "Autonomy": {
        "content": "本次主題：建模前的「自主性 (Autonomy) / 人為監督」指標評估。定義：確保人類在 AI 系統運作中保有最終控制權，此階段著重於『定義人機協作模式』與『規劃人工審核的介入點』。(共 7 題)\n\n"
      },
      "Privacy": {
        "content": "本次主題：建模前的「隱私 (Privacy)」指標評估。定義：在 AI 模型的生命週期中尊重並保護個人資訊，此階段著重於『資料蒐集的合法性』、『去識別化』與『儲存安全』。(共 6 題)\n\n"
      },
      "Fairness": {
        "content": "本次主題：建模前的「公平性 (Fairness)」指標評估。定義：確保 AI 系統在決策過程中不會對特定群體產生偏見或歧視，此階段著重於『分析原始資料集的代表性』與『檢測潛在歷史偏誤』。(共 5 題)\n\n"
      },
      "Security": {
        "content": "本次主題：建模前的「資訊安全 (Security)」指標評估。定義：防止外部環境對 AI 模型的入侵與損害，此階段著重於『保護訓練資料的存取安全』與『開發環境的權限管控』。(共 3 題)\n\n"
      }
    },
    "建模中": {
      "Accuracy": {
        "content": "本次主題：建模中的「準確性 (Accuracy)」指標評估。定義：AI 判斷的結果與真實情況相近程度，此階段著重於『資料品質』與『真實代表性』。(共 2 題)\n\n"
      },
      "Reliability": {
        "content": "本次主題：建模中的「可靠性 (Reliability)」指標評估。定義：AI 模型在面對不同類型干擾或異常情況時的穩定性，此階段著重於『資料來源的穩定』與『資料標註的一致性』。(共 4 題)\n\n"
      },
      "Safety": {
        "content": "本次主題：建模中的「安全性 (Safety)」指標評估。定義：AI 系統在預期使用或可預見的誤用情境下，不會造成非預期傷害，此階段著重於『定義系統的安全邊界』與『潛在危害風險評估』。(共 3 題)\n\n"
      },
      "Resilience": {
        "content": "本次主題：建模中的「韌性 (Resilience)」指標評估。定義：系統在遭遇攻擊或非預期錯誤時的承受與恢復能力，此階段著重於『規劃容錯架構』與『資料備份策略』。(共 1 題)\n\n"
      },
      "Transparency": {
        "content": "本次主題：建模中的「透明性 (Transparency)」指標評估。定義：AI 系統的決策過程應可被理解與追溯，此階段著重於『資料來源與處理流程的完整記錄』。(共 1 題)\n\n"
      },
      "Accountability": {
        "content": "本次主題：建模中的「當責性 (Accountability)」指標評估。定義：建立明確的責任歸屬與治理機制，此階段著重於『成立 AI 治理委員會』與『界定利害關係人及其職責』。(共 4 題)\n\n"
      },
      "Explainability": {
        "content": "本次主題：建模中的「可解譯性 (Explainability)」指標評估。定義：能向使用者或監管者提供 AI 決策依據的能力，此階段著重於『依據風險等級，定義模型需達到的可解譯程度』。(共 2 題)\n\n"
      },
      "Autonomy": {
        "content": "本次主題：建模中的「自主性 (Autonomy) / 人為監督」指標評估。定義：確保人類在 AI 系統運作中保有最終控制權，此階段著重於『定義人機協作模式』與『規劃人工審核的介入點』。(共 7 題)\n\n"
      },
      "Privacy": {
        "content": "本次主題：建模中的「隱私 (Privacy)」指標評估。定義：在 AI 模型的生命週期中尊重並保護個人資訊，此階段著重於『資料蒐集的合法性』、『去識別化』與『儲存安全』。(共 6 題)\n\n"
      },
      "Fairness": {
        "content": "本次主題：建模中的「公平性 (Fairness)」指標評估。定義：確保 AI 系統在決策過程中不會對特定群體產生偏見或歧視，此階段著重於『分析原始資料集的代表性』與『檢測潛在歷史偏誤』。(共 5 題)\n\n"
      },
      "Security": {
        "content": "本次主題：建模中的「資訊安全 (Security)」指標評估。定義：防止外部環境對 AI 模型的入侵與損害，此階段著重於『保護訓練資料的存取安全』與『開發環境的權限管控』。(共 5 題)\n\n"
      }
    },
    "建模後": {
      "Accuracy": {
        "content": "本次主題：建模後的「準確性 (Accuracy)」指標評估。定義：AI 判斷的結果與真實情況相近程度，此階段著重於『資料品質』與『真實代表性』。(共 7 題)\n\n"
      },
      "Reliability": {
        "content": "本次主題：建模後的「可靠性 (Reliability)」指標評估。定義：AI 模型在面對不同類型干擾或異常情況時的穩定性，此階段著重於『資料來源的穩定』與『資料標註的一致性』。(共 5 題)\n\n"
      },
      "Safety": {
        "content": "本次主題：建模後的「安全性 (Safety)」指標評估。定義：AI 系統在預期使用或可預見的誤用情境下，不會造成非預期傷害，此階段著重於『定義系統的安全邊界』與『潛在危害風險評估』。(共 6 題)\n\n"
      },
      "Resilience": {
        "content": "本次主題：建模後的「韌性 (Resilience)」指標評估。定義：系統在遭遇攻擊或非預期錯誤時的承受與恢復能力，此階段著重於『規劃容錯架構』與『資料備份策略』。(共 6 題)\n\n"
      },
      "Transparency": {
        "content": "本次主題：建模後的「透明性 (Transparency)」指標評估。定義：AI 系統的決策過程應可被理解與追溯，此階段著重於『資料來源與處理流程的完整記錄』。(共 4 題)\n\n"
      },
      "Accountability": {
        "content": "本次主題：建模後的「當責性 (Accountability)」指標評估。定義：建立明確的責任歸屬與治理機制，此階段著重於『成立 AI 治理委員會』與『界定利害關係人及其職責』。(共 7 題)\n\n"
      },
      "Explainability": {
        "content": "本次主題：建模後的「可解譯性 (Explainability)」指標評估。定義：能向使用者或監管者提供 AI 決策依據的能力，此階段著重於『依據風險等級，定義模型需達到的可解譯程度』。(共 5 題)\n\n"
      },
      "Autonomy": {
        "content": "本次主題：建模後的「自主性 (Autonomy) / 人為監督」指標評估。定義：確保人類在 AI 系統運作中保有最終控制權，此階段著重於『定義人機協作模式』與『規劃人工審核的介入點』。(共 7 題)\n\n"
      },
      "Privacy": {
        "content": "本次主題：建模後的「隱私 (Privacy)」指標評估。定義：在 AI 模型的生命週期中尊重並保護個人資訊，此階段著重於『資料蒐集的合法性』、『去識別化』與『儲存安全』。(共 5 題)\n\n"
      },
      "Fairness": {
        "content": "本次主題：建模後的「公平性 (Fairness)」指標評估。定義：確保 AI 系統在決策過程中不會對特定群體產生偏見或歧視，此階段著重於『分析原始資料集的代表性』與『檢測潛在歷史偏誤』。(共 6 題)\n\n"
      },
      "Security": {
        "content": "本次主題：建模後的「資訊安全 (Security)」指標評估。定義：防止外部環境對 AI 模型的入侵與損害，此階段著重於『保護訓練資料的存取安全』與『開發環境的權限管控』。(共 6 題)\n\n"
      }
    }
  }
}